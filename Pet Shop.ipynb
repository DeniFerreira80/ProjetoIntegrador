{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c948cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o Processo de Previsão de Demanda (Etapa 1: Configurações Iniciais) ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import unicodedata\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES INICIAIS ---\n",
    "FILE_INPUT = 'dados_ml_pronto.csv'\n",
    "TEST_SIZE_WEEKS = 15 # Últimas X semanas para teste/validação\n",
    "NUM_FUTURE_WEEKS = 12 # Número de semanas futuras para prever\n",
    "\n",
    "# Dicionário de colunas opcionais e seus valores padrão\n",
    "optional_cols = {\n",
    "    'decoracao': 0, 'instagram': 0, 'panfletos': 0, 'feriado': 0,\n",
    "    'pessoafisica': 0, 'empresa': 0, 'custo_total_campanhas': 0.0, 'preco_medio_venda': 0.0\n",
    "}\n",
    "\n",
    "# Início da execução\n",
    "print(\"--- Iniciando o Processo de Previsão de Demanda (Etapa 1: Configurações Iniciais) ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14fb31f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Funções auxiliares definidas. ---\n"
     ]
    }
   ],
   "source": [
    "# --- 2. FUNÇÕES AUXILIARES ---\n",
    "\n",
    "def normalize_col_names(df):\n",
    "    \"\"\"Normaliza nomes de colunas para minúsculas e snake_case.\"\"\"\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        normalized_col = unicodedata.normalize('NFKD', col).encode('ascii', 'ignore').decode('utf-8').lower()\n",
    "        new_cols.append(normalized_col.replace(' ', '_').replace('.', '').replace('/', '_').replace('(', '').replace(')', ''))\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "def create_time_features(df_input):\n",
    "    \"\"\"Cria features de séries temporais (ano, mês, semana, lags, médias móveis).\"\"\"\n",
    "    df_features = df_input.copy()\n",
    "\n",
    "    # Features de Data\n",
    "    df_features['Ano'] = df_features.index.year\n",
    "    df_features['Mes'] = df_features.index.month\n",
    "    df_features['DiaDaSemana'] = df_features.index.dayofweek\n",
    "    df_features['SemanaDoAno'] = df_features.index.isocalendar().week.astype(int)\n",
    "\n",
    "    # Features de Lag e Média Móvel (aplicadas apenas à 'quantidade_real')\n",
    "    for i in range(1, 4):\n",
    "        df_features[f'Lag_Quantidade_{i}S'] = df_features['quantidade_real'].shift(i)\n",
    "    \n",
    "    df_features['MediaMovel_Quantidade_4S'] = df_features['quantidade_real'].rolling(window=4, min_periods=1).mean()\n",
    "    df_features['MediaMovel_Quantidade_8S'] = df_features['quantidade_real'].rolling(window=8, min_periods=1).mean()\n",
    "\n",
    "    # Feature 'SemanasSinceLastSale'\n",
    "    df_features.loc[:, 'SemanasSinceLastSale'] = 0\n",
    "    weeks_since_last = 0\n",
    "    for idx, row in df_features.iterrows():\n",
    "        if row['quantidade_real'] > 0:\n",
    "            weeks_since_last = 0\n",
    "        else:\n",
    "            weeks_since_last += 1\n",
    "        df_features.loc[idx, 'SemanasSinceLastSale'] = weeks_since_last\n",
    "    \n",
    "    df_features['VendaNaSemanaAnterior'] = (df_features['Lag_Quantidade_1S'] > 0).astype(int)\n",
    "\n",
    "    # Preenche NaNs resultantes dos lags iniciais (primeiras linhas) com 0\n",
    "    df_features.fillna(0, inplace=True) \n",
    "    return df_features\n",
    "\n",
    "print(\"--- Funções auxiliares definidas. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8766722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e pré-processando o arquivo de entrada...\n",
      "Arquivo 'dados_ml_pronto.csv' carregado com sucesso para o produto: 'Petisco Natural de Frango 500g'.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. CARREGAMENTO E PRÉ-PROCESSAMENTO INICIAL DOS DADOS ---\n",
    "print(\"Carregando e pré-processando o arquivo de entrada...\")\n",
    "try:\n",
    "    df_raw = pd.read_csv(FILE_INPUT, sep=',', decimal='.', parse_dates=['SemanaAno'], dayfirst=True)\n",
    "    df_raw = normalize_col_names(df_raw)\n",
    "\n",
    "    df_raw.rename(columns={'semanaano': 'Timestamp'}, inplace=True)\n",
    "    df_raw.set_index('Timestamp', inplace=True)\n",
    "    df_raw.sort_index(inplace=True)\n",
    "\n",
    "    if 'quantidade' in df_raw.columns:\n",
    "        df_raw.rename(columns={'quantidade': 'quantidade_real'}, inplace=True)\n",
    "    elif 'quantidade_real' not in df_raw.columns:\n",
    "        print(\"ERRO: Coluna de quantidade ('Quantidade' ou 'quantidade_real') não encontrada no CSV.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if 'produto' in df_raw.columns:\n",
    "        df_raw.rename(columns={'produto': 'nome_produto'}, inplace=True)\n",
    "    elif 'nome_produto' not in df_raw.columns:\n",
    "        print(\"ERRO: Coluna 'Produto' ou 'nome_produto' não encontrada no CSV de entrada.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Validação para um único produto\n",
    "    if df_raw['nome_produto'].nunique() != 1:\n",
    "        print(f\"ERRO: O arquivo '{FILE_INPUT}' deve conter dados de APENAS UM PRODUTO. Encontrados: {df_raw['nome_produto'].unique()}\")\n",
    "        sys.exit(1)\n",
    "    PRODUCT_NAME = df_raw['nome_produto'].iloc[0]\n",
    "\n",
    "    df_raw['quantidade_real'] = pd.to_numeric(df_raw['quantidade_real'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    if df_raw['quantidade_real'].sum() == 0:\n",
    "        print(f\"ALERTA CRÍTICO: A coluna 'quantidade_real' para o produto '{PRODUCT_NAME}' contém apenas zeros. Verifique seu CSV.\")\n",
    "        \n",
    "    print(f\"Arquivo '{FILE_INPUT}' carregado com sucesso para o produto: '{PRODUCT_NAME}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo '{FILE_INPUT}' não encontrado. Verifique o caminho e o nome do arquivo.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"ERRO inesperado ao carregar ou pré-processar o arquivo: {e}. Verifique o formato do CSV (separador, decimal) e nomes das colunas.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1c13674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completando séries temporais com semanas ausentes e padronizando colunas...\n",
      "Séries temporais completadas. Total de semanas para o produto: 53.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deni\\AppData\\Local\\Temp\\ipykernel_1052\\3723250017.py:41: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_product_processed['preco_medio_venda'] = df_product_processed['preco_medio_venda'].fillna(method='ffill').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. GARANTIR SÉRIES TEMPORAIS CONTÍNUAS E PADRONIZAR COLUNAS ADICIONAIS ---\n",
    "print(\"Completando séries temporais com semanas ausentes e padronizando colunas...\")\n",
    "\n",
    "# Garante que o índice é um DatetimeIndex para operações de série temporal\n",
    "if not isinstance(df_raw.index, pd.DatetimeIndex):\n",
    "    df_raw.index = pd.to_datetime(df_raw.index)\n",
    "\n",
    "start_date = df_raw.index.min()\n",
    "end_date = df_raw.index.max()\n",
    "\n",
    "# Ajusta o range de datas para cobrir semanas completas (segunda a domingo)\n",
    "start_date_aligned = start_date - pd.Timedelta(days=start_date.dayofweek)\n",
    "end_date_aligned = end_date + pd.Timedelta(days=(6 - end_date.dayofweek) if end_date.dayofweek != 6 else 0)\n",
    "\n",
    "full_date_range = pd.date_range(start=start_date_aligned, end=end_date_aligned, freq='W-MON')\n",
    "\n",
    "# Cria DataFrame processado, garantindo que os dados originais sejam preservados\n",
    "df_product_processed = pd.DataFrame(index=full_date_range)\n",
    "df_product_processed.index.name = 'Timestamp'\n",
    "df_product_processed = df_product_processed.join(df_raw[['quantidade_real', 'nome_produto']], how='left')\n",
    "\n",
    "# Preenche NaNs de quantidade_real e nome_produto para as semanas ausentes\n",
    "df_product_processed['quantidade_real'] = df_product_processed['quantidade_real'].fillna(0).astype(int)\n",
    "df_product_processed['nome_produto'] = df_product_processed['nome_produto'].fillna(PRODUCT_NAME)\n",
    "\n",
    "# Tratamento de colunas de flags e custos\n",
    "for col, default_val in optional_cols.items():\n",
    "    if col in df_raw.columns:\n",
    "        df_product_processed[col] = df_raw[col].reindex(df_product_processed.index).fillna(default_val)\n",
    "        if col in ['decoracao', 'instagram', 'panfletos', 'feriado', 'pessoafisica', 'empresa']:\n",
    "            df_product_processed[col] = df_product_processed[col].astype(int)\n",
    "    else:\n",
    "        df_product_processed[col] = default_val\n",
    "\n",
    "# Renomeia 'custocampanha' se existir\n",
    "if 'custocampanha' in df_product_processed.columns and 'custo_total_campanhas' not in df_product_processed.columns:\n",
    "    df_product_processed.rename(columns={'custocampanha': 'custo_total_campanhas'}, inplace=True)\n",
    "\n",
    "# Preenchimento forward-fill para 'preco_medio_venda' se houver dados, senão 0\n",
    "if 'preco_medio_venda' in df_product_processed.columns:\n",
    "    df_product_processed['preco_medio_venda'] = df_product_processed['preco_medio_venda'].fillna(method='ffill').fillna(0)\n",
    "else:\n",
    "    df_product_processed['preco_medio_venda'] = 0\n",
    "\n",
    "df_product_processed = df_product_processed.sort_index()\n",
    "print(f\"Séries temporais completadas. Total de semanas para o produto: {len(df_product_processed)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "661478b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando features de séries temporais (lags, médias móveis e outras)...\n",
      "Features criadas. Total de features para o modelo: 19.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. ENGENHARIA DE FEATURES ---\n",
    "print(\"Criando features de séries temporais (lags, médias móveis e outras)...\")\n",
    "df_features = create_time_features(df_product_processed)\n",
    "\n",
    "features_to_exclude = ['quantidade_real', 'nome_produto']\n",
    "X = df_features.drop(columns=[col for col in features_to_exclude if col in df_features.columns], errors='ignore')\n",
    "y = df_features['quantidade_real']\n",
    "\n",
    "feature_columns = X.columns.tolist()\n",
    "\n",
    "if X.empty or y.empty:\n",
    "    print(\"ERRO: O DataFrame de features (X) ou o target (y) está vazio. Verifique os dados de entrada e processamento.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Features criadas. Total de features para o modelo: {len(feature_columns)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1ec2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividindo dados em treino e teste (últimas 15 semanas para teste)...\n",
      "Período de Treino: 01/01/2024 a 16/09/2024 (38 semanas)\n",
      "Período de Teste:  23/09/2024 a 30/12/2024 (15 semanas)\n"
     ]
    }
   ],
   "source": [
    "# --- 6. DIVISÃO DOS DADOS EM TREINO E TESTE (TIME-SERIES SPLIT) ---\n",
    "print(f\"Dividindo dados em treino e teste (últimas {TEST_SIZE_WEEKS} semanas para teste)...\")\n",
    "\n",
    "if len(X) <= TEST_SIZE_WEEKS:\n",
    "    print(f\"AVISO: O número total de semanas ({len(X)}) é menor ou igual ao número de semanas para teste ({TEST_SIZE_WEEKS}). Ajustando TEST_SIZE_WEEKS para {len(X) - 1 if len(X) > 1 else 1}.\")\n",
    "    TEST_SIZE_WEEKS = max(1, len(X) - 1)\n",
    "\n",
    "X_train = X.iloc[:-TEST_SIZE_WEEKS]\n",
    "X_test = X.iloc[-TEST_SIZE_WEEKS:]\n",
    "y_train = y.iloc[:-TEST_SIZE_WEEKS]\n",
    "y_test = y.iloc[-TEST_SIZE_WEEKS:]\n",
    "\n",
    "if X_train.empty or X_test.empty or y_train.empty or y_test.empty:\n",
    "    print(\"ERRO: A divisão de treino/teste resultou em conjuntos vazios. Ajuste 'TEST_SIZE_WEEKS'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Período de Treino: {X_train.index.min().strftime('%d/%m/%Y')} a {X_train.index.max().strftime('%d/%m/%Y')} ({len(X_train)} semanas)\")\n",
    "print(f\"Período de Teste:  {X_test.index.min().strftime('%d/%m/%Y')} a {X_test.index.max().strftime('%d/%m/%Y')} ({len(X_test)} semanas)\")\n",
    "\n",
    "if y_train.sum() == 0:\n",
    "    print(\"ALERTA: O conjunto de treino não contém vendas (todos os valores são zero). O modelo aprenderá a prever zero.\")\n",
    "if y_test.sum() == 0:\n",
    "    print(\"ALERTA: O conjunto de teste não contém vendas (todos os valores são zero). As métricas de avaliação serão 0 ou NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b03343a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "     *** Treinando o Modelo XGBoost (Sem Otimização de Hiperparâmetros) *** \n",
      "==================================================\n",
      "Treinamento do modelo XGBoost concluído.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 7. TREINAMENTO DO MODELO XGBoost (Sem GridSearchCV) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** Treinando o Modelo XGBoost (Sem Otimização de Hiperparâmetros) *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Configurando o modelo XGBoost com parâmetros que tendem a dar bons resultados (padrão ou ligeiramente ajustados)\n",
    "# Estes são os parâmetros que provavelmente estavam ativos quando você obteve o R² de 59%\n",
    "model = XGBRegressor(objective='reg:squarederror', \n",
    "                     eval_metric='mae', \n",
    "                     random_state=42, \n",
    "                     n_jobs=-1,\n",
    "                     n_estimators=100,  # Exemplo de um número razoável de estimadores\n",
    "                     learning_rate=0.1, # Exemplo de uma taxa de aprendizado padrão\n",
    "                     max_depth=3)      # Exemplo de uma profundidade de árvore padrão\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Treinamento do modelo XGBoost concluído.\")\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2de159a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "     *** Treinando o Modelo XGBoost (Com Ajustes para Variação) *** \n",
      "==================================================\n",
      "Treinamento do modelo XGBoost concluído com ajustes.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 7. TREINAMENTO DO MODELO XGBoost (Ajuste para Forçar Variação Futura) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** Treinando o Modelo XGBoost (Com Ajustes para Variação) *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Tentando ajustar parâmetros para forçar mais variação nas previsões futuras\n",
    "model = XGBRegressor(objective='reg:squarederror', \n",
    "                     eval_metric='mae', \n",
    "                     random_state=42, \n",
    "                     n_jobs=-1,\n",
    "                     n_estimators=200,      # Aumentado para dar mais chance ao modelo\n",
    "                     learning_rate=0.05,    # Diminuído para um aprendizado mais gradual\n",
    "                     max_depth=5,           # Aumentado para permitir mais complexidade\n",
    "                     min_child_weight=0.5,  # Reduzido para permitir divisões com menor peso (mais sensível a dados esparsos)\n",
    "                     gamma=0.01,            # Pequena regularização, mas não muito alta\n",
    "                     subsample=0.8,         # Usa 80% das amostras para cada árvore\n",
    "                     colsample_bytree=0.8)  # Usa 80% das features para cada árvore\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Treinamento do modelo XGBoost concluído com ajustes.\")\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8528fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "     *** RESULTADOS DAS MÉTRICAS (XGBoost Treinado) *** \n",
      "==================================================\n",
      "R-squared (R²): 0.7619\n",
      "MAE (Mean Absolute Error): 0.67\n",
      "MAPE (Mean Absolute Percentage Error): 17.82%\n",
      "==================================================\n",
      "\n",
      "--- Importância das Features (Top 15) ---\n",
      "pessoafisica                0.283383\n",
      "empresa                     0.156970\n",
      "panfletos                   0.089147\n",
      "MediaMovel_Quantidade_4S    0.076717\n",
      "Lag_Quantidade_1S           0.068478\n",
      "decoracao                   0.060901\n",
      "Mes                         0.060555\n",
      "MediaMovel_Quantidade_8S    0.052029\n",
      "SemanaDoAno                 0.035472\n",
      "Lag_Quantidade_2S           0.034125\n",
      "Lag_Quantidade_3S           0.033924\n",
      "feriado                     0.025909\n",
      "instagram                   0.022392\n",
      "preco_medio_venda           0.000000\n",
      "Ano                         0.000000\n",
      "dtype: float32\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "     *** EXPORTANDO DADOS DE TESTE PARA CSV *** \n",
      "==================================================\n",
      "Arquivo 'resultados_teste_xgboost_Petisco_Natural_de_Frango_500g.csv' com resultados do teste exportado com sucesso!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 8. AVALIAÇÃO DE DESEMPENHO DO MODELO ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** RESULTADOS DAS MÉTRICAS (XGBoost Treinado) *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# INICIALIZAÇÃO DE VARIÁVEIS (Adicionar estas 3 linhas)\n",
    "r2 = np.nan\n",
    "mae = np.nan\n",
    "mape = np.nan\n",
    "\n",
    "y_pred_test_raw = model.predict(X_test)\n",
    "# Ajuste para prever zero e arredondar\n",
    "y_pred_test = np.round(y_pred_test_raw).clip(min=0)\n",
    "y_pred_test[y_pred_test < 0.5] = 0 # Define como 0 se a previsão for menor que 0.5\n",
    "y_pred_test = y_pred_test.astype(int)\n",
    "\n",
    "if not y_test.empty and y_pred_test.size > 0:\n",
    "    y_test_original = y_test.values\n",
    "\n",
    "    if np.std(y_test_original) == 0:\n",
    "        r2 = np.nan\n",
    "        print(\"AVISO: Desvio padrão dos valores reais no teste é zero. R-squared não calculado.\")\n",
    "    else:\n",
    "        r2 = r2_score(y_test_original, y_pred_test)\n",
    "        print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "    mae = mean_absolute_error(y_test_original, y_pred_test)\n",
    "    print(f\"MAE (Mean Absolute Error): {mae:.2f}\")\n",
    "\n",
    "    mape = np.nan\n",
    "    non_zero_indices = (y_test_original != 0)\n",
    "    if np.sum(non_zero_indices) > 0:\n",
    "        mape = np.mean(np.abs((y_test_original[non_zero_indices] - y_pred_test[non_zero_indices]) / y_test_original[non_zero_indices])) * 100\n",
    "        print(f\"MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "    else:\n",
    "        print(\"MAPE: Não calculado (todos os valores reais no teste são zero).\")\n",
    "else:\n",
    "    print(\"AVISO: Conjuntos de teste ou predições vazios para cálculo de métricas.\")\n",
    "print(\"==================================================\")\n",
    "\n",
    "print(\"\\n--- Importância das Features (Top 15) ---\")\n",
    "if len(feature_columns) > 0:\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=feature_columns).sort_values(ascending=False)\n",
    "    print(feature_importances.head(15))\n",
    "else:\n",
    "    print(\"Não há features para exibir a importância.\")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# --- 8.1. EXPORTANDO DADOS DE TESTE (REAL vs. PREDITO) PARA CSV ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** EXPORTANDO DADOS DE TESTE PARA CSV *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Criando um DataFrame com os resultados do teste\n",
    "df_test_results = pd.DataFrame({\n",
    "    'Timestamp': y_test.index.strftime('%d/%m/%Y'),\n",
    "    'Produto': PRODUCT_NAME,\n",
    "    'Real': y_test.values,\n",
    "    'Predito': y_pred_test\n",
    "})\n",
    "\n",
    "# Definindo o nome do arquivo de saída\n",
    "safe_product_name = unicodedata.normalize('NFKD', PRODUCT_NAME).encode('ascii', 'ignore').decode('utf-8')\n",
    "safe_product_name = safe_product_name.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\")\n",
    "test_output_filename = f'resultados_teste_xgboost_{safe_product_name}.csv'\n",
    "\n",
    "# Exportando para CSV\n",
    "df_test_results.to_csv(test_output_filename, index=False, encoding='utf-8-sig', sep=';')\n",
    "\n",
    "print(f\"Arquivo '{test_output_filename}' com resultados do teste exportado com sucesso!\")\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "509f4e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando previsões para as próximas 12 semanas (previsão base sem eventos simulados)...\n",
      "Previsões futuras (base sem eventos simulados) geradas.\n"
     ]
    }
   ],
   "source": [
    "# --- 9. PREVISÃO PARA SEMANAS FUTURAS ---\n",
    "print(f\"\\nRealizando previsões para as próximas {NUM_FUTURE_WEEKS} semanas (previsão base sem eventos simulados)...\")\n",
    "\n",
    "last_historical_date = df_product_processed.index.max()\n",
    "future_dates = pd.date_range(start=last_historical_date + pd.Timedelta(weeks=1),\n",
    "                            periods=NUM_FUTURE_WEEKS, freq='W-MON')\n",
    "\n",
    "df_combined_for_features = df_product_processed.copy()\n",
    "\n",
    "future_predictions_list = []\n",
    "lower_bounds_list = []\n",
    "upper_bounds_list = []\n",
    "\n",
    "# Loop para prever cada semana futura, atualizando as features recursivamente\n",
    "for i in range(NUM_FUTURE_WEEKS):\n",
    "    current_future_date = future_dates[i]\n",
    "    \n",
    "    # 1. Cria um esqueleto da linha futura com base na última semana histórica ou padrão\n",
    "    temp_future_row = pd.DataFrame(index=[current_future_date])\n",
    "    temp_future_row['nome_produto'] = PRODUCT_NAME\n",
    "    temp_future_row['quantidade_real'] = 0 # Placeholder para a previsão\n",
    "    \n",
    "    # Preenche colunas opcionais para o futuro:\n",
    "    # Flags de campanhas/feriados ficam em 0 por padrão, sem simulação aqui.\n",
    "    # Outros valores como preco_medio_venda e custo_total_campanhas usam o último valor conhecido.\n",
    "    for col, default_val in optional_cols.items():\n",
    "        if col in df_product_processed.columns:\n",
    "            if col in ['decoracao', 'instagram', 'panfletos', 'feriado', 'pessoafisica', 'empresa']:\n",
    "                temp_future_row[col] = 0 # Mantém em 0 para a previsão base\n",
    "            elif col in ['preco_medio_venda', 'custo_total_campanhas']:\n",
    "                # Usa o último valor conhecido da série histórica para estas colunas\n",
    "                temp_future_row[col] = df_product_processed[col].iloc[-1] if not df_product_processed[col].empty else default_val\n",
    "            else: \n",
    "                temp_future_row[col] = df_product_processed[col].iloc[-1] if not df_product_processed[col].empty else default_val\n",
    "        else:\n",
    "            temp_future_row[col] = default_val\n",
    "\n",
    "    # 2. Adiciona a semana futura temporariamente ao dataframe combinado\n",
    "    df_combined_for_features = pd.concat([df_combined_for_features, temp_future_row])\n",
    "    \n",
    "    # 3. Recalcula as features para TODO o dataframe combinado (para pegar lags/MM corretos para a semana atual)\n",
    "    # Importante: Criamos um DF temporário com a última linha para gerar features apenas para ela\n",
    "    X_current_future_features = create_time_features(df_combined_for_features.tail(1)) \n",
    "    \n",
    "    # Garante que as colunas da feature estejam na ordem correta do treinamento\n",
    "    X_current_future = X_current_future_features.reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "    # 4. Faz a previsão\n",
    "    pred_raw = model.predict(X_current_future)\n",
    "    \n",
    "    # Ajuste para prever zero e arredondar\n",
    "    pred_value = np.round(pred_raw[0]).clip(min=0)\n",
    "    if pred_value < 0.5:\n",
    "        pred_value = 0\n",
    "    else:\n",
    "        pred_value = int(pred_value)\n",
    "\n",
    "    # Margem de erro baseada no MAE do teste (reusando o 'mae' calculado na seção 8)\n",
    "    # Usamos np.nan_to_num para garantir que não haja NaN se mae for NaN\n",
    "    error_margin_for_bounds = mae if 'mae' in locals() and not np.isnan(mae) else (y_train.std() * 0.5 if y_train.std() > 0 else 0)\n",
    "\n",
    "    lower_bound_raw = pred_raw[0] - error_margin_for_bounds\n",
    "    upper_bound_raw = pred_raw[0] + error_margin_for_bounds\n",
    "    \n",
    "    lower_bound = np.round(lower_bound_raw).clip(min=0)\n",
    "    if lower_bound < 0.5:\n",
    "        lower_bound = 0\n",
    "    else:\n",
    "        lower_bound = int(lower_bound)\n",
    "\n",
    "    upper_bound = np.round(upper_bound_raw).clip(min=0)\n",
    "    if upper_bound < 0.5:\n",
    "        upper_bound = 0\n",
    "    else:\n",
    "        upper_bound = int(upper_bound)\n",
    "\n",
    "    future_predictions_list.append(pred_value)\n",
    "    lower_bounds_list.append(lower_bound)\n",
    "    upper_bounds_list.append(upper_bound)\n",
    "\n",
    "    # 5. Atualiza 'quantidade_real' no DataFrame combinado com a previsão para a próxima iteração\n",
    "    df_combined_for_features.loc[current_future_date, 'quantidade_real'] = pred_value\n",
    "\n",
    "print(\"Previsões futuras (base sem eventos simulados) geradas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11acc451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Montando DataFrame final para exportação...\n",
      "\n",
      "Arquivo 'previsoes_demanda_xgboost_Petisco_Natural_de_Frango_500g.csv' exportado com sucesso!\n",
      "\n",
      "==================================================\n",
      "     *** IMPACTO ESTIMADO DE EVENTOS (Cenários Simulados) *** \n",
      "==================================================\n",
      "- Feriado: Impacto de 0.00% (Base Bruta: 1.58 -> Simulada Bruta: 1.58 | Arredondado: 2 -> 2)\n",
      "- Instagram: Impacto de 1.44% (Base Bruta: 1.58 -> Simulada Bruta: 1.60 | Arredondado: 2 -> 2)\n",
      "- Decoracao: Impacto de 9.93% (Base Bruta: 1.58 -> Simulada Bruta: 1.73 | Arredondado: 2 -> 2)\n",
      "- Panfletos: Impacto de 3.66% (Base Bruta: 1.58 -> Simulada Bruta: 1.63 | Arredondado: 2 -> 2)\n",
      "==================================================\n",
      "\n",
      "--- FIM DO ALGORITMO ---\n"
     ]
    }
   ],
   "source": [
    "# --- 10. CONSTRUIR DATAFRAME FINAL PARA EXPORTAÇÃO ---\n",
    "print(\"\\nMontando DataFrame final para exportação...\")\n",
    "\n",
    "df_final_export = df_product_processed[['quantidade_real']].copy()\n",
    "df_final_export.rename(columns={'quantidade_real': 'Valores reais (divisao de validacao)'}, inplace=True)\n",
    "df_final_export['nome_produto'] = PRODUCT_NAME\n",
    "df_final_export['Valores preditos'] = np.nan\n",
    "df_final_export['Valores de previsao'] = np.nan\n",
    "df_final_export['Lower_Bound'] = np.nan\n",
    "df_final_export['Upper_Bound'] = np.nan\n",
    "\n",
    "# Popula os valores preditos no período de teste\n",
    "df_final_export.loc[y_test.index, 'Valores preditos'] = y_pred_test\n",
    "\n",
    "# Adiciona as previsões futuras e seus intervalos\n",
    "df_future_results = pd.DataFrame({\n",
    "    'Valores de previsao': future_predictions_list,\n",
    "    'Lower_Bound': lower_bounds_list,\n",
    "    'Upper_Bound': upper_bounds_list\n",
    "}, index=future_dates)\n",
    "df_future_results['nome_produto'] = PRODUCT_NAME\n",
    "\n",
    "# Concatena o histórico com as previsões futuras\n",
    "df_final_export = pd.concat([df_final_export, df_future_results], axis=0, ignore_index=False)\n",
    "df_final_export = df_final_export.sort_index()\n",
    "\n",
    "output_columns_order = [\n",
    "    'Timestamp',\n",
    "    'nome_produto',\n",
    "    'Valores reais (divisao de validacao)',\n",
    "    'Valores preditos',\n",
    "    'Valores de previsao',\n",
    "    'Lower_Bound',\n",
    "    'Upper_Bound'\n",
    "]\n",
    "df_final_export['Timestamp'] = df_final_export.index.strftime('%d/%m/%Y')\n",
    "\n",
    "for col in output_columns_order:\n",
    "    if col not in df_final_export.columns:\n",
    "        df_final_export[col] = np.nan\n",
    "\n",
    "df_final_export = df_final_export[output_columns_order]\n",
    "\n",
    "# Formata as colunas numéricas para string com duas casas decimais ou inteiro se for exato\n",
    "for col in ['Valores reais (divisao de validacao)', 'Valores preditos', 'Valores de previsao', 'Lower_Bound', 'Upper_Bound']:\n",
    "    df_final_export[col] = df_final_export[col].astype(float).apply(\n",
    "        lambda x: f\"{int(x)}\".replace('.', ',') if pd.notna(x) and x == int(x) else (f\"{x:.2f}\".replace('.', ',') if pd.notna(x) else '')\n",
    "    )\n",
    "\n",
    "# --- 11. EXPORTAR O DATAFRAME FINAL PARA CSV ---\n",
    "safe_product_name = unicodedata.normalize('NFKD', PRODUCT_NAME).encode('ascii', 'ignore').decode('utf-8')\n",
    "safe_product_name = safe_product_name.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\")\n",
    "output_filename = f'previsoes_demanda_xgboost_{safe_product_name}.csv'\n",
    "\n",
    "df_final_export.to_csv(output_filename, index=False, encoding='utf-8-sig', sep=';')\n",
    "\n",
    "print(f\"\\nArquivo '{output_filename}' exportado com sucesso!\")\n",
    "\n",
    "# --- 12. CÁLCULO DE IMPACTO PERCENTUAL DE CAMPANHAS E FERIADO (SIMULADO) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** IMPACTO ESTIMADO DE EVENTOS (Cenários Simulados) *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Para calcular o impacto, vamos criar a \"base_prediction_row\"\n",
    "# simulando a primeira semana futura sem NENHUM evento/campanha ativado,\n",
    "# e então ativaremos cada feature para ver o impacto.\n",
    "\n",
    "# Cria uma linha de features para a primeira semana futura sem NENHUM evento/campanha\n",
    "first_future_date = future_dates[0]\n",
    "temp_base_future_row = pd.DataFrame(index=[first_future_date])\n",
    "temp_base_future_row['nome_produto'] = PRODUCT_NAME\n",
    "temp_base_future_row['quantidade_real'] = 0 # Não importa para gerar features, é um placeholder\n",
    "\n",
    "for col, default_val in optional_cols.items():\n",
    "    if col in df_product_processed.columns:\n",
    "        if col in ['decoracao', 'instagram', 'panfletos', 'feriado', 'pessoafisica', 'empresa']:\n",
    "            temp_base_future_row[col] = 0 # Garante que essas flags são 0 para a BASE\n",
    "        elif col in ['preco_medio_venda', 'custo_total_campanhas']:\n",
    "            temp_base_future_row[col] = df_product_processed[col].iloc[-1] if not df_product_processed[col].empty else default_val\n",
    "        else:\n",
    "            temp_base_future_row[col] = df_product_processed[col].iloc[-1] if not df_product_processed[col].empty else default_val\n",
    "    else:\n",
    "        temp_base_future_row[col] = default_val\n",
    "\n",
    "# Gera as features para esta \"linha base\" futura\n",
    "base_future_features = create_time_features(pd.concat([df_product_processed, temp_base_future_row]))\n",
    "\n",
    "# A base_prediction_row é a última linha das features geradas (correspondente a first_future_date)\n",
    "base_prediction_row_for_model = base_future_features.tail(1).reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "# A previsão base é a previsão da primeira semana futura sem eventos simulados\n",
    "base_prediction_value_raw = model.predict(base_prediction_row_for_model)[0]\n",
    "# Usamos o valor bruto para calcular o impacto percentual\n",
    "base_prediction_value_for_impact = base_prediction_value_raw\n",
    "\n",
    "# Função auxiliar para calcular e imprimir o impacto (AGORA COM VALORES DECIMAIS NO CÁLCULO)\n",
    "def calculate_and_print_impact_decimal(feature_name, simulated_value_feature):\n",
    "    temp_simulated_row = base_prediction_row_for_model.copy()\n",
    "    temp_simulated_row.loc[:, feature_name] = simulated_value_feature # Usa .loc para evitar SettingWithCopyWarning\n",
    "    \n",
    "    simulated_prediction_value_raw = model.predict(temp_simulated_row)[0]\n",
    "    \n",
    "    # Valores para exibição arredondados para inteiros, como você venderia\n",
    "    base_display = np.round(base_prediction_value_raw).clip(min=0).astype(int)\n",
    "    simulated_display = np.round(simulated_prediction_value_raw).clip(min=0).astype(int)\n",
    "\n",
    "    # Cálculo do impacto percentual usando valores brutos (decimais)\n",
    "    if base_prediction_value_for_impact == 0:\n",
    "        if simulated_prediction_value_raw > 0:\n",
    "            impact_str = \"Infinito (de 0 para >0)\"\n",
    "        else:\n",
    "            impact_str = \"0.00%\" # Continua zero\n",
    "    else:\n",
    "        impact_percent = ((simulated_prediction_value_raw - base_prediction_value_for_impact) / base_prediction_value_for_impact) * 100\n",
    "        impact_str = f\"{impact_percent:.2f}%\"\n",
    "\n",
    "    print(f\"- {feature_name.replace('_', ' ').title()}: Impacto de {impact_str} (Base Bruta: {base_prediction_value_for_impact:.2f} -> Simulada Bruta: {simulated_prediction_value_raw:.2f} | Arredondado: {base_display} -> {simulated_display})\")\n",
    "\n",
    "# Simulações de impacto\n",
    "calculate_and_print_impact_decimal('feriado', 1)\n",
    "calculate_and_print_impact_decimal('instagram', 1)\n",
    "calculate_and_print_impact_decimal('decoracao', 1)\n",
    "calculate_and_print_impact_decimal('panfletos', 1)\n",
    "\n",
    "print(\"==================================================\")\n",
    "print(\"\\n--- FIM DO ALGORITMO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08240b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "     *** LINHA DE RESUMO AUTOMATIZADA *** \n",
      "==================================================\n",
      "Produto\tR-squared (R²)\tMAE\tMAPE\tFeriado\tInstagram\tDecoração\tPanfletos\n",
      "Petisco Natural de Frango 500g\t0.7619\t0.67\t17.82%\t-5.04%\t18.47%\t-1.77%\t5.41%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 13. GERAR LINHA DE RESUMO AUTOMATIZADA ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** LINHA DE RESUMO AUTOMATIZADA *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Coletando os valores que já estão disponíveis das etapas anteriores\n",
    "product_name_for_summary = PRODUCT_NAME # Já definido no início do script\n",
    "\n",
    "# Formatando r2, mae e mape diretamente de suas variáveis numéricas\n",
    "r_squared_summary = f\"{r2:.4f}\" if not pd.isna(r2) else \"N/A\"\n",
    "mae_summary = f\"{mae:.2f}\" if not pd.isna(mae) else \"N/A\"\n",
    "mape_summary = f\"{mape:.2f}%\" if not pd.isna(mape) else \"N/A\" # Usamos 'mape' (numérico) e adicionamos '%' aqui\n",
    "\n",
    "\n",
    "# Capturando e formatando os impactos percentuais do dicionário 'impact_results' da Etapa 12\n",
    "# Esta parte não precisa de alteração se 'impact_results' já está sendo preenchido na Etapa 12.\n",
    "feriado_impact = f\"{impact_results.get('feriado', 0.0):.2f}%\" if not pd.isna(impact_results.get('feriado')) and impact_results.get('feriado') != float('inf') else \"Infinito\" if impact_results.get('feriado') == float('inf') else \"0.00%\"\n",
    "instagram_impact = f\"{impact_results.get('instagram', 0.0):.2f}%\" if not pd.isna(impact_results.get('instagram')) and impact_results.get('instagram') != float('inf') else \"Infinito\" if impact_results.get('instagram') == float('inf') else \"0.00%\"\n",
    "decoracao_impact = f\"{impact_results.get('decoracao', 0.0):.2f}%\" if not pd.isna(impact_results.get('decoracao')) and impact_results.get('decoracao') != float('inf') else \"Infinito\" if impact_results.get('decoracao') == float('inf') else \"0.00%\"\n",
    "panfletos_impact = f\"{impact_results.get('panfletos', 0.0):.2f}%\" if not pd.isna(impact_results.get('panfletos')) and impact_results.get('panfletos') != float('inf') else \"Infinito\" if impact_results.get('panfletos') == float('inf') else \"0.00%\"\n",
    "\n",
    "\n",
    "# Imprime o cabeçalho da tabela\n",
    "print(\"Produto\\tR-squared (R²)\\tMAE\\tMAPE\\tFeriado\\tInstagram\\tDecoração\\tPanfletos\")\n",
    "# Imprime a linha de resultados para o produto atual\n",
    "print(f\"{product_name_for_summary}\\t{r_squared_summary}\\t{mae_summary}\\t{mape_summary}\\t{feriado_impact}\\t{instagram_impact}\\t{decoracao_impact}\\t{panfletos_impact}\")\n",
    "\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e44df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "     *** EXPORTANDO LINHA DE RESUMO PARA CSV *** \n",
      "==================================================\n",
      "Linha de resumo exportada para 'resumo_metrics_impact_Petisco_Natural_de_Frango_500g.csv' com sucesso!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 14. EXPORTAR LINHA DE RESUMO PARA CSV ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"     *** EXPORTANDO LINHA DE RESUMO PARA CSV *** \")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# Dados da linha de resumo (usando as variáveis já definidas na Etapa 13)\n",
    "summary_data = {\n",
    "    'Produto': [product_name_for_summary],\n",
    "    'R-squared (R²)': [r_squared_summary],\n",
    "    'MAE': [mae_summary],\n",
    "    'MAPE': [mape_summary],\n",
    "    'Feriado': [feriado_impact],\n",
    "    'Instagram': [instagram_impact],\n",
    "    'Decoração': [decoracao_impact],\n",
    "    'Panfletos': [panfletos_impact]\n",
    "}\n",
    "\n",
    "# Criar DataFrame a partir dos dados\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Nome do arquivo de saída. Adicionaremos o nome do produto para cada linha ser única.\n",
    "safe_product_name = unicodedata.normalize('NFKD', PRODUCT_NAME).encode('ascii', 'ignore').decode('utf-8')\n",
    "safe_product_name = safe_product_name.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\".\", \"\")\n",
    "summary_output_filename = f'resumo_metrics_impact_{safe_product_name}.csv'\n",
    "\n",
    "# Exportar para CSV\n",
    "# Usamos 'a' (append) para adicionar linhas a um arquivo existente, e 'header=False'\n",
    "# para não reescrever o cabeçalho após a primeira execução, se o arquivo já existir.\n",
    "# Se o arquivo não existir, ele será criado e o cabeçalho será escrito na primeira vez.\n",
    "# Isso exige um pequeno ajuste para a primeira linha, veja a nota abaixo.\n",
    "df_summary.to_csv(summary_output_filename, mode='a', header=not os.path.exists(summary_output_filename), index=False, encoding='utf-8-sig', sep=';')\n",
    "\n",
    "print(f\"Linha de resumo exportada para '{summary_output_filename}' com sucesso!\")\n",
    "print(\"==================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
